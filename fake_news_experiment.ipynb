{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import required libraries</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "import datetime\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.multiprocessing\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "\n",
    "# import torchvision\n",
    "# from torchvision import transforms\n",
    "\n",
    "from transformers import AutoModel, AutoModelWithLMHead, AutoModelForCausalLM, pipeline\n",
    "#from datasets import load_dataset, load_from_disk\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments, Trainer\n",
    "from accelerate import Accelerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Set required env and global variables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\"\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"2\"\n",
    "os.environ[\"MASTER_PORT\"] = \"29580\"\n",
    "os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 7\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data-preprocessing<h/2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize individual databases and then combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df = pd.read_csv(\"True.csv\")\n",
    "fake_df = pd.read_csv(\"Fake.csv\")\n",
    "mix_df = pd.read_csv(\"WELFake_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  \n",
       "0  December 31, 2017   \n",
       "1  December 29, 2017   \n",
       "2  December 31, 2017   \n",
       "3  December 30, 2017   \n",
       "4  December 29, 2017   "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1           1                                                NaN   \n",
       "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "\n",
       "                                                text  label  \n",
       "0  No comment is expected from Barack Obama Membe...      1  \n",
       "1     Did they post their votes for Hillary already?      1  \n",
       "2   Now, most of the demonstrators gathered last ...      1  \n",
       "3  A dozen politically active pastors came here f...      0  \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  \n",
       "0  December 31, 2017  \n",
       "1  December 31, 2017  \n",
       "2  December 30, 2017  \n",
       "3  December 29, 2017  \n",
       "4  December 25, 2017  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21417 23481 72134\n"
     ]
    }
   ],
   "source": [
    "print(len(true_df), len(fake_df), len(mix_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the layout of the datasets, the common features are 'text' and 'title'. Combining these 3 different datasets into a test and train dataset.\n",
    "\n",
    "// TODO : Can 'title' can be included as a feature?\n",
    "\n",
    "WEL_database has their label flipped. So need ot reverse that in the following helper funtion. \n",
    "\n",
    "// TODO : explain why they're flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vanilla_datasets():\n",
    "    true_df = pd.read_csv(\"True.csv\")\n",
    "    fake_df = pd.read_csv(\"Fake.csv\")\n",
    "    train_df = pd.read_csv(\"WELFake_Dataset.csv\")\n",
    "\n",
    "    # drop columns that will not be used.\n",
    "    true_df = true_df.drop(columns=[\"subject\", \"date\", \"title\"])\n",
    "    fake_df = fake_df.drop(columns=[\"subject\", \"date\", \"title\"])\n",
    "    train_df = train_df.drop(columns=[\"Unnamed: 0\", \"title\"])    \n",
    "\n",
    "    # add a 'label' columns\n",
    "    true_df['label'] = 1\n",
    "    fake_df['label'] = 0\n",
    "\n",
    "    # concatinate 'true' and 'fake' news datasets\n",
    "    combined_df = pd.concat([true_df, fake_df])\n",
    "\n",
    "    # clean dataframes \n",
    "    combined_df = combined_df.dropna()\n",
    "    train_df = train_df.dropna()\n",
    "\n",
    "    # flip labels for mix_df\n",
    "    train_df['label'] = train_df[\"label\"] ^ 1 # XOR operation flips 1 and 0\n",
    "\n",
    "    # shuffle databases\n",
    "    train_df = train_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "    combined_df = combined_df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "    train_df.name = \"vanilla training dataset\"\n",
    "    combined_df.name = \"vanilla testing dataset\"\n",
    "\n",
    "    return train_df, combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = get_vanilla_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  No comment is expected from Barack Obama Membe...      0\n",
       "1     Did they post their votes for Hillary already?      0\n",
       "2   Now, most of the demonstrators gathered last ...      0\n",
       "3  A dozen politically active pastors came here f...      1\n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The parent company for the conservative Fox Ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BERLIN (Reuters) - U.S. President Donald Trump...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEW DELHI (Reuters) - India could take up the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A member of the House Intelligence Committee i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When your presidential candidate is supported ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  The parent company for the conservative Fox Ne...      0\n",
       "1  BERLIN (Reuters) - U.S. President Donald Trump...      1\n",
       "2  NEW DELHI (Reuters) - India could take up the ...      1\n",
       "3  A member of the House Intelligence Committee i...      0\n",
       "4  When your presidential candidate is supported ...      0"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_sample = true_df['text'][0]\n",
    "fake_sample = fake_df['text'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM-Stylize articles to generate adversarial input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_real_prompts(passages):\n",
    "    messages = []\n",
    "    for passage in passages:\n",
    "\n",
    "        sys_message = \"You are a writing AI assistant. Rewrite the provided text with official language. Respond only with the rewritten passage.\"\n",
    "        user_message = \"Respond only with the rewritten passage. Here is the passage: \\n {}. \".format(passage)\n",
    "\n",
    "        message = [\n",
    "            { \"role\" : \"system\", \"content\" : sys_message},\n",
    "            { \"role\" : \"user\", \"content\" : user_message}\n",
    "            ]\n",
    "        messages.append(message)\n",
    "    return messages\n",
    "\n",
    "def build_fake_prompts(passages):\n",
    "    messages = []\n",
    "    for passage in passages:\n",
    "\n",
    "        sys_message = \"You are a writing AI assistant. Rewrite the provided text like a scammer. Respond only with the rewritten passage.\"\n",
    "        user_message = \"Respond only with the rewritten passage. Here is the passage: \\n {}. \".format(passage)\n",
    "\n",
    "        message = [\n",
    "            { \"role\" : \"system\", \"content\" : sys_message},\n",
    "            { \"role\" : \"user\", \"content\" : user_message}\n",
    "            ]\n",
    "        messages.append(message)\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf1bc2f9c5341768209a2666541fef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\" # better adherence to instructions\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\", \n",
    "    model=model_id, \n",
    "    model_kwargs={\"torch_dtype\" : torch.bfloat16}, \n",
    "    device_map=\"auto\",\n",
    "    max_new_tokens=512,\n",
    "    return_full_text=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to generate LLm stylized datasets.\n",
    "\n",
    "def get_batch_of_articles(index, data):\n",
    "    batch_size = 10\n",
    "    ret = []\n",
    "    start = index*batch_size\n",
    "    for i in range(batch_size):\n",
    "        ret.append(data['text'][start+i])\n",
    "    return ret\n",
    "\n",
    "def get_responses(messages):\n",
    "    llm_responses = []\n",
    "    for message in messages:\n",
    "        llm_response = message[0]['generated_text']\n",
    "        llm_responses.append(llm_response)\n",
    "    return llm_responses\n",
    "\n",
    "def generate_llm_stylized(makeFake):\n",
    "    filename = \"fake2real_output\" if makeFake else \"rea2fake_output\"\n",
    "    header = ['text']\n",
    "    for i in range(20):\n",
    "        articles = get_batch_of_articles(i, fake_df)\n",
    "        msgs = []\n",
    "        if makeFake:\n",
    "            msgs = build_real_prompts(articles)\n",
    "        else:\n",
    "            msgs = build_fake_prompts(articles)\n",
    "        responses = pipe(msgs)\n",
    "        llm_articles = get_responses(responses)\n",
    "        f_name = filename+\"_\"+str(i)+\".csv\"\n",
    "        with open(f_name, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(header)\n",
    "            for item in llm_articles:\n",
    "                writer.writerow([item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_llm_stylized(makeFake=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_llm_stylized_v2(makeFake):\n",
    "    filename = \"fake2real_output\" if makeFake else \"real2fake_output\"\n",
    "    db = fake_df if makeFake else true_df\n",
    "    header = ['text']\n",
    "    for i in range(20):\n",
    "        articles = get_batch_of_articles(i, db)\n",
    "        msgs = []\n",
    "        if makeFake:\n",
    "            msgs = build_real_prompts(articles)\n",
    "        else:\n",
    "            msgs = build_fake_prompts(articles)\n",
    "        responses = pipe(msgs)\n",
    "        llm_articles = get_responses(responses)\n",
    "        f_name = filename+\"_\"+str(i)+\".csv\"\n",
    "        with open(f_name, mode='w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(header)\n",
    "            for item in llm_articles:\n",
    "                writer.writerow([item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_llm_stylized_v2(makeFake=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_texts = []\n",
    "fake_texts = []\n",
    "for i in range(200):\n",
    "    real_texts.append(true_df['text'][i][0:500])\n",
    "    fake_texts.append(fake_df['text'][i][0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2r_csv_files = [os.path.join(\".\", f) for f in os.listdir(\".\") if f.startswith(\"fake2real\")]\n",
    "r2f_csv_files = [os.path.join(\".\", f) for f in os.listdir(\".\") if f.startswith(\"real2fake\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2r_combined_df = pd.concat([pd.read_csv(file) for file in f2r_csv_files])\n",
    "r2f_combined_df = pd.concat([pd.read_csv(file) for file in r2f_csv_files])\n",
    "\n",
    "f2r_combined_df['label'] = 0\n",
    "r2f_combined_df['label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adversarial_dataset():\n",
    "\n",
    "    r2f_combined_df.to_csv(\"real2fake.csv\")\n",
    "    f2r_combined_df.to_csv(\"fake2real.csv\")\n",
    "\n",
    "    real2fake_df = pd.read_csv(\"real2fake.csv\", index_col=0).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "    fake2real_df = pd.read_csv(\"fake2real.csv\", index_col=0).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "    llm_df = pd.concat([real2fake_df, fake2real_df]).sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "    llm_df.name = \"LLM Stylized dataset\"\n",
    "    real2fake_df.name = \"Real2Fake LLM dataset\"\n",
    "    fake2real_df.name = \"Fake2Real LLM dataset\"\n",
    "\n",
    "    return llm_df, real2fake_df, fake2real_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_df, r2f_df, f2r_df = get_adversarial_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test a variety of models to evaluate their performance on datasets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "MODEL_1 = \"jy46604790/Fake-News-Bert-Detect\"\n",
    "MODEL_2 = \"winterForestStump/Roberta-fake-news-detector\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(model_id, text):\n",
    "    # if model_id == MODEL_1:\n",
    "    #     text = text[0:500]\n",
    "    return text\n",
    "\n",
    "def model_prediction(clf_model, text):\n",
    "    # if clf_model.model.name_or_path == MODEL_1:\n",
    "        # print(type(text))\n",
    "    encoding = clf_model.tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(DEVICE)\n",
    "    output = clf_model.model(**encoding)\n",
    "    logits = output.logits\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    predicted_label = torch.argmax(probs, dim=-1)\n",
    "    predicted_label = predicted_label.item()\n",
    "\n",
    "    return predicted_label\n",
    "\n",
    "\n",
    "def establish_performance(model_id, df, debug=False):\n",
    "    clf = pipeline(\"text-classification\", model=model_id, tokenizer=model_id, device=DEVICE)\n",
    "    count = 0\n",
    "    max_len = len(df)\n",
    "    if debug:\n",
    "        max_len = 500\n",
    "    for i in range(max_len):\n",
    "        text = model_input(model_id=model_id, text=df['text'][i])\n",
    "        res = model_prediction(clf_model=clf, text=text)\n",
    "        # print(res, _df['label'][i])\n",
    "        if res == df['label'][i]:\n",
    "            count += 1\n",
    "    acc = (count * 100) / max_len\n",
    "    print(\"Accuracy of model {} on {} is {}\".format(model_id, df.name, acc))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model jy46604790/Fake-News-Bert-Detect on vanilla trainset is 85.2\n",
      "Accuracy of model jy46604790/Fake-News-Bert-Detect on vanilla test set is 100.0\n",
      "Accuracy of model jy46604790/Fake-News-Bert-Detect on Real2Fake LLM dataset is 2.5\n",
      "Accuracy of model jy46604790/Fake-News-Bert-Detect on Fake2Real LLM dataset is 99.5\n",
      "Accuracy of model jy46604790/Fake-News-Bert-Detect on LLM Stylized dataset is 51.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "establish_performance(MODEL_1, train_df, debug=True)\n",
    "establish_performance(MODEL_1, test_df, debug=True)\n",
    "establish_performance(MODEL_1, r2f_df)\n",
    "establish_performance(MODEL_1, f2r_df)\n",
    "establish_performance(MODEL_1, llm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model winterForestStump/Roberta-fake-news-detector on vanilla trainset is 70.8\n",
      "Accuracy of model winterForestStump/Roberta-fake-news-detector on vanilla test set is 84.0\n",
      "Accuracy of model winterForestStump/Roberta-fake-news-detector on Real2Fake LLM dataset is 10.0\n",
      "Accuracy of model winterForestStump/Roberta-fake-news-detector on Fake2Real LLM dataset is 57.5\n",
      "Accuracy of model winterForestStump/Roberta-fake-news-detector on LLM Stylized dataset is 33.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33.75"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "establish_performance(MODEL_2, train_df, debug=True)\n",
    "establish_performance(MODEL_2, test_df, debug=True)\n",
    "establish_performance(MODEL_2, r2f_df)\n",
    "establish_performance(MODEL_2, f2r_df)\n",
    "establish_performance(MODEL_2, llm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Finetune BERT </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504d1815ab294a139376c1c4ba4e03b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/72095 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d391b276a8845e99e2203e53ddd5ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/44898 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Step 1: Convert Pandas DataFrame to Hugging Face Dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "# Step 2: Initialize the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Step 3: Tokenization function\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# Step 4: Apply the tokenization to the datasets using `map()` with `batched=True`\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Step 5: Rename the label column to 'labels' (required by the model)\n",
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Step 6: Set the format to PyTorch (torch tensors)\n",
    "train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "# Now your datasets are ready for use with Hugging Face's Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b8f79e38874dbbb001cfff7c50f12f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grads/a/atkulkarni/MIPS/mips/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "DistStoreError",
     "evalue": "Timed out after 1801 seconds waiting for clients. 1/2 clients joined.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDistStoreError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[171], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./results\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m          \u001b[49m\u001b[38;5;66;43;03m# Output directory for model checkpoints\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Evaluate once per epoch\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Learning rate for optimization\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Batch size for training\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Batch size for evaluation\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Number of epochs\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# Weight decay for regularization\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./logs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Directory for storing logs\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# Log every 10 steps\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:134\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001b[0m\n",
      "File \u001b[0;32m~/MIPS/mips/lib/python3.12/site-packages/transformers/training_args.py:1773\u001b[0m, in \u001b[0;36mTrainingArguments.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1771\u001b[0m \u001b[38;5;66;03m# Initialize device before we proceed\u001b[39;00m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_torch_available():\n\u001b[0;32m-> 1773\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;66;03m# Disable average tokens when using single device\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage_tokens_across_devices:\n",
      "File \u001b[0;32m~/MIPS/mips/lib/python3.12/site-packages/transformers/training_args.py:2299\u001b[0m, in \u001b[0;36mTrainingArguments.device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2296\u001b[0m \u001b[38;5;124;03mThe device used by this process.\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2298\u001b[0m requires_backends(\u001b[38;5;28mself\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m-> 2299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_devices\u001b[49m\n",
      "File \u001b[0;32m~/MIPS/mips/lib/python3.12/site-packages/transformers/utils/generic.py:60\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, attr, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28msetattr\u001b[39m(obj, attr, cached)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cached\n",
      "File \u001b[0;32m~/MIPS/mips/lib/python3.12/site-packages/transformers/training_args.py:2229\u001b[0m, in \u001b[0;36mTrainingArguments._setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_deepspeed:\n\u001b[1;32m   2228\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCELERATE_USE_DEEPSPEED\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2229\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_state \u001b[38;5;241m=\u001b[39m \u001b[43mPartialState\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maccelerator_state_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_deepspeed:\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCELERATE_USE_DEEPSPEED\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/MIPS/mips/lib/python3.12/site-packages/accelerate/state.py:212\u001b[0m, in \u001b[0;36mPartialState.__init__\u001b[0;34m(self, cpu, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;66;03m# Deal with all other backends but XPU and CPU, that gets handled special later\u001b[39;00m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    209\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (DistributedType\u001b[38;5;241m.\u001b[39mMULTI_XPU, DistributedType\u001b[38;5;241m.\u001b[39mMULTI_CPU)\n\u001b[1;32m    210\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mis_initialized()\n\u001b[1;32m    211\u001b[0m         ):\n\u001b[0;32m--> 212\u001b[0m             \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_process_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# XPU and CPU require special env configs to be set\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;129;01min\u001b[39;00m (DistributedType\u001b[38;5;241m.\u001b[39mMULTI_XPU, DistributedType\u001b[38;5;241m.\u001b[39mMULTI_CPU):\n",
      "File \u001b[0;32m~/MIPS/mips/lib/python3.12/site-packages/torch/distributed/c10d_logger.py:83\u001b[0m, in \u001b[0;36m_exception_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     85\u001b[0m         msg_dict \u001b[38;5;241m=\u001b[39m _get_msg_dict(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/MIPS/mips/lib/python3.12/site-packages/torch/distributed/c10d_logger.py:97\u001b[0m, in \u001b[0;36m_time_logger.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[1;32m     96\u001b[0m     t1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns()\n\u001b[0;32m---> 97\u001b[0m     func_return \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime_ns() \u001b[38;5;241m-\u001b[39m t1\n\u001b[1;32m    100\u001b[0m     msg_dict \u001b[38;5;241m=\u001b[39m _get_msg_dict(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/MIPS/mips/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py:1520\u001b[0m, in \u001b[0;36minit_process_group\u001b[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options, device_id)\u001b[0m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m store \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1517\u001b[0m     rendezvous_iterator \u001b[38;5;241m=\u001b[39m rendezvous(\n\u001b[1;32m   1518\u001b[0m         not_none(init_method), rank, world_size, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m   1519\u001b[0m     )\n\u001b[0;32m-> 1520\u001b[0m     store, rank, world_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrendezvous_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m     store\u001b[38;5;241m.\u001b[39mset_timeout(timeout)\n\u001b[1;32m   1523\u001b[0m     \u001b[38;5;66;03m# Use a PrefixStore to avoid accidental overrides of keys used by\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m     \u001b[38;5;66;03m# different systems (e.g. RPC) in case the store is multi-tenant.\u001b[39;00m\n",
      "File \u001b[0;32m~/MIPS/mips/lib/python3.12/site-packages/torch/distributed/rendezvous.py:269\u001b[0m, in \u001b[0;36m_env_rendezvous_handler\u001b[0;34m(url, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m master_port \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(_get_env_or_raise(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMASTER_PORT\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    267\u001b[0m use_libuv \u001b[38;5;241m=\u001b[39m _get_use_libuv_from_query_dict(query_dict)\n\u001b[0;32m--> 269\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43m_create_c10d_store\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaster_addr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaster_port\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_libuv\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m (store, rank, world_size)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# If this configuration is invalidated, there is nothing we can do about it\u001b[39;00m\n",
      "File \u001b[0;32m~/MIPS/mips/lib/python3.12/site-packages/torch/distributed/rendezvous.py:189\u001b[0m, in \u001b[0;36m_create_c10d_store\u001b[0;34m(hostname, port, rank, world_size, timeout, use_libuv)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     start_daemon \u001b[38;5;241m=\u001b[39m rank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTCPStore\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart_daemon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_tenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_libuv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_libuv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mDistStoreError\u001b[0m: Timed out after 1801 seconds waiting for clients. 1/2 clients joined."
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Output directory for model checkpoints\n",
    "    evaluation_strategy=\"epoch\",     # Evaluate once per epoch\n",
    "    learning_rate=2e-5,              # Learning rate for optimization\n",
    "    per_device_train_batch_size=8,   # Batch size for training\n",
    "    per_device_eval_batch_size=8,    # Batch size for evaluation\n",
    "    num_train_epochs=3,              # Number of epochs\n",
    "    weight_decay=0.01,               # Weight decay for regularization\n",
    "    logging_dir='./logs',            # Directory for storing logs\n",
    "    logging_steps=10,                # Log every 10 steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         # The pre-trained model\n",
    "    args=training_args,                  # Training arguments\n",
    "    train_dataset=train_dataset,         # Training dataset\n",
    "    eval_dataset=test_dataset,           # Evaluation dataset\n",
    "    tokenizer=tokenizer,                 # Tokenizer for padding/truncation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mips",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
